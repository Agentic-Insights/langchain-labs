{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Tutorial: Getting Started\n",
    "\n",
    "## Welcome to Your LangChain Journey!\n",
    "\n",
    "In this notebook, we'll explore LangChain, a powerful library for working with large language models. We'll start with the basics and progressively build more complex applications.\n",
    "\n",
    "Let's begin by setting up our environment and importing the necessary libraries.\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Agentic-Insights/langchain-labs/blob/main/labs/001-tutorial.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the OpenAI API key from the environment variables\n",
    "load_dotenv()\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    # If the key is not found in the environment variables, try to get it from Google Colab userdata\n",
    "    from google.colab import userdata\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
    "    if os.environ[\"OPENAI_API_KEY\"] is None:\n",
    "        print(\"OPENAI_API_KEY not found in environment variables or Google Colab userdata.\")\n",
    "else:\n",
    "    print(\"OpenAI API key found in environment variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our language model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "response = llm.invoke(\"Say hello to the world of LangChain!\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You've just set up your first LangChain environment. \n",
    "\n",
    "**Run this cell, and you should see a friendly greeting from the AI.**\n",
    "\n",
    "Next, we'll explore how to create more structured interactions using PromptTemplates and Chains. Ready to dive deeper?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cod-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
